{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sas1Vdg0PJiP",
        "colab_type": "text"
      },
      "source": [
        "Install Google pre-trained BERT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f94gBXStMs52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bert-serving-client\n",
        "!pip install -U bert-serving-server[http]\n",
        "!wget https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip\n",
        "!unzip chinese_L-12_H-768_A-12.zip\n",
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip\n",
        "!unzip cased_L-24_H-1024_A-16.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNTasbcQPljb",
        "colab_type": "text"
      },
      "source": [
        "Install sentence transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6OKWCUvld5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -U sentence-transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tZf0y8YPuHY",
        "colab_type": "text"
      },
      "source": [
        "Connect to BERT server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opFjsy-dOFfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nohup bert-serving-start -model_dir=./chinese_L-12_H-768_A-12 > out.file 2>&1 &"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8j2XLO1P_ve",
        "colab_type": "text"
      },
      "source": [
        "Download and import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P8ZZG7HNDat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os.path import exists\n",
        "if not exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp7tTaMRRZKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(path):\n",
        "  with open(path) as dataset:\n",
        "    raw_data=dataset.readlines()\n",
        "    return raw_data\n",
        "\n",
        "raw_english_train=read_data(\"./train.enzh.src\")\n",
        "raw_chinese_train=read_data(\"./train.enzh.mt\")\n",
        "zh_train_scores =read_data(\"./train.enzh.scores\")\n",
        "\n",
        "raw_english_val = read_data(\"./dev.enzh.src\")\n",
        "raw_chinese_val = read_data(\"./dev.enzh.mt\")\n",
        "zh_val_scores = read_data(\"./dev.enzh.scores\")\n",
        "sentence_embeddings_train = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhHBkPvIp60t",
        "colab_type": "text"
      },
      "source": [
        "Use **Sentence Transformer** to do English word embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wumdsi3OlxOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "embedding = SentenceTransformer('bert-large-nli-mean-tokens')\n",
        "zh_train_src = np.array(embedding.encode(raw_english_train))\n",
        "zh_val_src = np.array(embedding.encode(raw_english_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv4NQBp_qVhT",
        "colab_type": "text"
      },
      "source": [
        "Use **BERT-Chinese** to do Chinese embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfywvXamRG7L",
        "colab_type": "code",
        "outputId": "af095e71-5f60-4069-b5fe-edc0c2117883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from bert_serving.client import BertClient\n",
        "bc = BertClient()\n",
        "zh_train_mt = bc.encode(raw_chinese_train)\n",
        "zh_val_mt = bc.encode(raw_chinese_val)\n",
        "\n",
        "bc.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
            "here is what you can do:\n",
            "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
            "- or, start a new server with a larger \"max_seq_len\"\n",
            "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB3iuKm2S80R",
        "colab_type": "code",
        "outputId": "6595e34f-422d-4163-91d9-a59ee83c6e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(zh_train_src.shape)\n",
        "print(zh_train_mt.shape)\n",
        "print(zh_val_src.shape)\n",
        "print(zh_val_mt.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7000, 1024)\n",
            "(7000, 768)\n",
            "(1000, 1024)\n",
            "(1000, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF80wR9Pw7Us",
        "colab_type": "text"
      },
      "source": [
        "Combine two languages together and get the training input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfnsm8GYTlFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "X_train_zh= np.concatenate((zh_train_src,zh_train_mt),axis = 1)\n",
        "\n",
        "\n",
        "\n",
        "X_val_zh = np.concatenate((zh_val_src,zh_val_mt),axis = 1)\n",
        "\n",
        "#Scores\n",
        "train_scores = np.array(zh_train_scores).astype(float)\n",
        "y_train_zh =train_scores\n",
        "# pre = preprocessing.MinMaxScaler()\n",
        "# y_train_zh = pre.fit_transform(y_train_zh)\n",
        "# y_train_zh = y_train_zh.reshape(7000,)\n",
        "\n",
        "val_scores = np.array(zh_val_scores).astype(float)\n",
        "y_val_zh =val_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46F9BJomWVAV",
        "colab_type": "code",
        "outputId": "5a0ef6f4-5690-4cee-ed4e-0f96c475fc6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(X_train_zh.shape)\n",
        "print(X_val_zh.shape)\n",
        "print(y_train_zh.shape)\n",
        "print(y_val_zh.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7000, 1792)\n",
            "(1000, 1792)\n",
            "(7000,)\n",
            "(1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3OrCZdKy9Vj",
        "colab_type": "text"
      },
      "source": [
        "SVM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvQs2ihuXPRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTAMLgo4Xcg_",
        "colab_type": "code",
        "outputId": "87824ed3-06db-4349-861c-0403234d4852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "for k in ['rbf']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    print('Start training:')\n",
        "    clf_t.fit(X_train_zh, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training:\n",
            "rbf\n",
            "RMSE: 0.8581345136057762 Pearson 0.4106063417749696\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLvy7yCozHR0",
        "colab_type": "text"
      },
      "source": [
        "Use **Keras** to build a fully connected neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ivnr_xQaw0n",
        "colab_type": "code",
        "outputId": "2d283f7a-f648-425e-bf9f-a57779b641c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D,Dropout, Activation, Flatten,MaxPooling2D\n",
        "from scipy.stats.stats import pearsonr\n",
        "def baseline_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128,input_dim=1792,init='normal', activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(32,init='normal', activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(8,init='normal', activation='relu'))\n",
        "    model.add(Dense(1, init='normal'))\n",
        "      # Compile model\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy']) \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d4wP8456rKD",
        "colab_type": "text"
      },
      "source": [
        "Train and test the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7hhRp-66pH1",
        "colab_type": "code",
        "outputId": "0550d76f-4cc1-4461-c562-e93b126b3a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "model = baseline_model()\n",
        "model.fit(X_train_zh, y_train_zh, nb_epoch=5, batch_size=64,validation_data=(X_val_zh,y_val_zh))\n",
        "predictions = model.predict(X_val_zh)\n",
        "predictions = predictions.astype(np.float64).reshape(1000,)\n",
        "print(predictions.shape)\n",
        "pearson = pearsonr(y_val_zh, predictions)\n",
        "print(f'Pearson {pearson[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, input_dim=1792, activation=\"relu\", kernel_initializer=\"normal\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", kernel_initializer=\"normal\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"normal\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 1000 samples\n",
            "Epoch 1/5\n",
            "7000/7000 [==============================] - 1s 119us/step - loss: 0.8498 - acc: 0.0000e+00 - val_loss: 0.7816 - val_acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "7000/7000 [==============================] - 0s 59us/step - loss: 0.7796 - acc: 0.0000e+00 - val_loss: 0.7413 - val_acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "7000/7000 [==============================] - 0s 61us/step - loss: 0.7418 - acc: 0.0000e+00 - val_loss: 0.6933 - val_acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "7000/7000 [==============================] - 0s 63us/step - loss: 0.7155 - acc: 0.0000e+00 - val_loss: 0.7070 - val_acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "7000/7000 [==============================] - 0s 58us/step - loss: 0.7000 - acc: 0.0000e+00 - val_loss: 0.6832 - val_acc: 0.0000e+00\n",
            "(1000,)\n",
            "Pearson 0.4171055394873464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOm6GtWO0mVg",
        "colab_type": "text"
      },
      "source": [
        "Test prediction and download the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiuAQfUxaPpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def writeScores(method_name,scores):\n",
        "    fn = \"predictions.txt\"\n",
        "    print(\"\")\n",
        "    with open(fn, 'w') as output_file:\n",
        "        for idx,x in enumerate(scores):\n",
        "            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n",
        "            #print(out)\n",
        "            output_file.write(f\"{x}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q21_-wMqN_i",
        "colab_type": "code",
        "outputId": "4bbb0522-8f3d-4970-c144-b1016cbf7e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "#EN_ZH\n",
        "english_test_path='./test.enzh.src'\n",
        "chinese_test_path='./test.enzh.mt'\n",
        "raw_english_test=read_data(english_test_path)\n",
        "raw_chinese_test=read_data(chinese_test_path)\n",
        "zh_test_src = embedding.encode(raw_english_test)\n",
        "bc = BertClient()\n",
        "zh_test_mt = bc.encode(raw_chinese_test)\n",
        "bc.close()\n",
        "X_test_zh= np.concatenate((np.array(zh_test_src),np.array(zh_test_mt)),axis=1) \n",
        "\n",
        "#Predict\n",
        "predictions = model.predict(X_test_zh)\n",
        "predictions_zh = predictions.astype(np.float64).reshape(1000,)\n",
        "print(predictions_zh.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
            "here is what you can do:\n",
            "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
            "- or, start a new server with a larger \"max_seq_len\"\n",
            "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUg5irbWqvkM",
        "colab_type": "code",
        "outputId": "23241a23-30c9-4e6d-b9fc-9124a9b29d9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "writeScores(\"FCNN\",predictions_zh)\n",
        "\n",
        "with ZipFile(\"en-zh_fcnn.zip\",\"w\") as newzip:\n",
        "\tnewzip.write(\"predictions.txt\")\n",
        " \n",
        "files.download('en-zh_fcnn.zip') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hO0SNwvKYNE",
        "colab_type": "text"
      },
      "source": [
        "Result\n",
        "\n",
        "The result from codalab after submitting is 0.4260."
      ]
    }
  ]
}